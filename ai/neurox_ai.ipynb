{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q google-genai"
      ],
      "metadata": {
        "id": "Hzo6ku7723by"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "OED882Wds2yW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "312a1f78-16a4-47a0-b257-d44c5e92eb02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GEMINI_API_KEY set: True\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"GEMINI_API_KEY\"] = \"PASTE_YOUR_REAL_GEMINI_API_KEY_HERE\"\n",
        "\n",
        "print(\"GEMINI_API_KEY set:\", \"GEMINI_API_KEY\" in os.environ)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "V8e6nGHj1seo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "import os\n",
        "\n",
        "client = genai.Client(\n",
        "    api_key=os.environ[\"GEMINI_API_KEY\"]\n",
        ")\n",
        "\n",
        "print(\"âœ… Gemini client initialized\")"
      ],
      "metadata": {
        "id": "vEIYUHRovn9o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe290120-163c-4761-9316-653c4005f9e7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Gemini client initialized\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clarify_message(text):\n",
        "    \"\"\"\n",
        "    NeuroX Communication Copilot\n",
        "    Rewrites messages to be clear, kind, professional,\n",
        "    and neurodiversity-friendly.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        response = client.models.generate_content(\n",
        "            model=\"gemini-1.5-flash\",\n",
        "            contents=f\"\"\"\n",
        "            Rewrite the message below to be:\n",
        "            - Clear\n",
        "            - Kind\n",
        "            - Professional\n",
        "            - Neurodiversity-friendly\n",
        "            - Low stress\n",
        "\n",
        "            Message:\n",
        "            {text}\n",
        "            \"\"\"\n",
        "        )\n",
        "        return response.text\n",
        "\n",
        "    except Exception as e:\n",
        "        # Safe fallback (never crash)\n",
        "        return (\n",
        "            \"Iâ€™m feeling a bit overwhelmed right now. \"\n",
        "            \"When you have time, Iâ€™d really appreciate your support.\"\n",
        "        )"
      ],
      "metadata": {
        "id": "9Wr-o8CJwOy3"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clarify_message(text):\n",
        "    \"\"\"\n",
        "    NeuroX Communication Copilot\n",
        "    Rewrites messages to be clear, kind, professional,\n",
        "    and neurodiversity-friendly.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        response = client.models.generate_content(\n",
        "            model=\"gemini-1.5-flash\",\n",
        "            contents=f\"\"\"\n",
        "            Rewrite the message below to be:\n",
        "            - Clear\n",
        "            - Kind\n",
        "            - Professional\n",
        "            - Neurodiversity-friendly\n",
        "            - Low stress\n",
        "\n",
        "            Message:\n",
        "            {text}\n",
        "            \"\"\"\n",
        "        )\n",
        "        return response.text\n",
        "\n",
        "    except Exception as e:\n",
        "        # Safe fallback (never crash)\n",
        "        return (\n",
        "            \"Iâ€™m feeling a bit overwhelmed right now. \"\n",
        "            \"When you have time, Iâ€™d really appreciate your support.\"\n",
        "        )"
      ],
      "metadata": {
        "id": "_cpxVlW-3RkI"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clarify_message(text):\n",
        "    \"\"\"\n",
        "    NeuroX Communication Copilot\n",
        "    Rewrites messages to be clear, kind, professional,\n",
        "    and neurodiversity-friendly.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        response = client.models.generate_content(\n",
        "            model=\"gemini-1.5-flash\",\n",
        "            contents=f\"\"\"\n",
        "            Rewrite the message below to be:\n",
        "            - Clear\n",
        "            - Kind\n",
        "            - Professional\n",
        "            - Neurodiversity-friendly\n",
        "            - Low stress\n",
        "\n",
        "            Message:\n",
        "            {text}\n",
        "            \"\"\"\n",
        "        )\n",
        "        return response.text\n",
        "\n",
        "    except Exception as e:\n",
        "        # Safe fallback (never crash)\n",
        "        return (\n",
        "            \"Iâ€™m feeling a bit overwhelmed right now. \"\n",
        "            \"When you have time, Iâ€™d really appreciate your support.\"\n",
        "        )"
      ],
      "metadata": {
        "id": "v0lPVaqF3T9a"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def burnout_check(hours_worked, tasks_done, breaks_taken):\n",
        "    \"\"\"\n",
        "    Simple, explainable burnout risk detection.\n",
        "    No diagnosis, no labels.\n",
        "    \"\"\"\n",
        "    score = (hours_worked / (breaks_taken + 1)) - tasks_done\n",
        "\n",
        "    if score >= 6:\n",
        "        return \"ğŸš¨ High burnout risk detected. Strongly recommend rest.\"\n",
        "    elif score >= 3:\n",
        "        return \"âš ï¸ Moderate workload. Consider a short break.\"\n",
        "    else:\n",
        "        return \"âœ… Healthy, sustainable pace\""
      ],
      "metadata": {
        "id": "wL-kJlFiwcE5"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_quest(task):\n",
        "    \"\"\"\n",
        "    Turns work into a NeuroX-style gamified quest.\n",
        "    \"\"\"\n",
        "    return {\n",
        "        \"quest\": task,\n",
        "        \"xp\": 10,\n",
        "        \"reward\": \"ğŸŒ± Focus Boost\",\n",
        "        \"rest_bonus\": True\n",
        "    }"
      ],
      "metadata": {
        "id": "9h6rDTAx3uR3"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"ğŸ§  Communication Copilot Output:\\n\")\n",
        "print(clarify_message(\"I am overwhelmed and nobody responds on time\"))\n",
        "\n",
        "print(\"\\nğŸ”¥ Burnout Check:\\n\")\n",
        "print(burnout_check(hours_worked=9, tasks_done=3, breaks_taken=1))\n",
        "\n",
        "print(\"\\nğŸ® Generated Quest:\\n\")\n",
        "print(generate_quest(\"Prepare excutive dashboard\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gup_39n43ymM",
        "outputId": "66c84067-464a-4966-d4a1-1a1c0a2a351d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ§  Communication Copilot Output:\n",
            "\n",
            "Iâ€™m feeling a bit overwhelmed right now. When you have time, Iâ€™d really appreciate your support.\n",
            "\n",
            "ğŸ”¥ Burnout Check:\n",
            "\n",
            "âœ… Healthy, sustainable pace\n",
            "\n",
            "ğŸ® Generated Quest:\n",
            "\n",
            "{'quest': 'Prepare excutive dashboard', 'xp': 10, 'reward': 'ğŸŒ± Focus Boost', 'rest_bonus': True}\n"
          ]
        }
      ]
    }
  ]
}